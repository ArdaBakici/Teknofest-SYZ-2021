{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\r\n",
    "import os \r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "from tqdm import trange\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Dataset Constants\r\n",
    "DATASET_SPLIT = [\"train\", \"val\", \"test\"]\r\n",
    "DATASET_PATH = \"./data/dataset1\"\r\n",
    "TRAIN_DIR = \"train\"\r\n",
    "VAL_DIR = \"validation\"\r\n",
    "TEST_DIR = \"test\"\r\n",
    "\r\n",
    "DATA_DIR = \"data\"\r\n",
    "LABEL_DIR = \"label\"\r\n",
    "\r\n",
    "IMG_EXT = \"png\"\r\n",
    "\r\n",
    "OUT_PATH = \"./outdata/tfrecord/\"\r\n",
    "\r\n",
    "CLASS_VALUES = [1, 2]\r\n",
    "\r\n",
    "MAX_FILES = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def image_feature(value):\r\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "    return tf.train.Feature(\r\n",
    "        bytes_list=tf.train.BytesList(value=[serialize_array(value)])\r\n",
    "    )\r\n",
    "\r\n",
    "def bytes_feature(value):\r\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "    if isinstance(value, type(tf.constant(0))):\r\n",
    "        value = value.numpy()\r\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "def float_feature(value):\r\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\r\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "def int64_feature(value):\r\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "def float_feature_list(value):\r\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\r\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\r\n",
    "\r\n",
    "def parse_tfrecord_fn(example):\r\n",
    "    feature_description = {\r\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\r\n",
    "        \"path\": tf.io.FixedLenFeature([], tf.string),\r\n",
    "        \"area\": tf.io.FixedLenFeature([], tf.float32),\r\n",
    "        \"bbox\": tf.io.VarLenFeature(tf.float32),\r\n",
    "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\r\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.int64),\r\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\r\n",
    "    }\r\n",
    "    example = tf.io.parse_single_example(example, feature_description)\r\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\r\n",
    "    example[\"bbox\"] = tf.sparse.to_dense(example[\"bbox\"])\r\n",
    "    return example\r\n",
    "\r\n",
    "# non keras\r\n",
    "def serialize_array(array):\r\n",
    "  array = tf.io.serialize_tensor(array).numpy()\r\n",
    "  return array"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def parse_single_image(image, label):\r\n",
    "  \r\n",
    "  #define the dictionary -- the structure -- of our single example\r\n",
    "  data = {\r\n",
    "        'image/height' : int64_feature(image.shape[0]),\r\n",
    "        'image/width' : int64_feature(image.shape[1]),\r\n",
    "        'image/depth' : int64_feature(image.shape[2]),\r\n",
    "        'image/raw_image' : image_feature(image),\r\n",
    "        'label/raw' : image_feature(label)\r\n",
    "    }\r\n",
    "  #create an Example, wrapping the single features\r\n",
    "  out = tf.train.Example(features=tf.train.Features(feature=data))\r\n",
    "  return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Processing Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def write_image_batches_to_tfr(img_path, label_path, filename:str=\"batch\", max_files:int=100, out_dir:str=\"/data/tfrecord/\"):\r\n",
    "    img_filenames = tf.io.gfile.glob(f\"{img_path}/*.{IMG_EXT}\")\r\n",
    "    random.shuffle(img_filenames)\r\n",
    "    label_filenames = []\r\n",
    "    for i in img_filenames:\r\n",
    "        label_filenames.append(i.replace(img_path, label_path))\r\n",
    "    # determine the number of shards (single TFRecord files) we need:\r\n",
    "    assert len(img_filenames) == len(label_filenames)\r\n",
    "    splits = (len(img_filenames)//max_files) + 1 #determine how many tfr shards are needed\r\n",
    "    if len(img_filenames)%max_files == 0:\r\n",
    "        splits-=1\r\n",
    "    print(f\"\\nUsing {splits} shard(s) for {len(img_filenames)} files, with up to {max_files} samples per shard\")\r\n",
    "    os.makedirs(out_dir, exist_ok=True)\r\n",
    "    file_count = 0\r\n",
    "    for i in trange(splits):\r\n",
    "        current_shard_name = f\"{out_dir}tfrecord_{i+1}in{splits}_{filename}.tfrecords\"\r\n",
    "        options = tf.io.TFRecordOptions(compression_type=\"ZLIB\")\r\n",
    "        writer = tf.io.TFRecordWriter(current_shard_name, options=options)\r\n",
    "\r\n",
    "        current_shard_count = 0\r\n",
    "        while current_shard_count < max_files: #as long as our shard is not full\r\n",
    "            #get the index of the file that we want to parse now\r\n",
    "            index = i*max_files+current_shard_count\r\n",
    "            if index == len(img_filenames): #when we have consumed the whole data, preempt generation\r\n",
    "                break\r\n",
    "            \r\n",
    "            #img = None\r\n",
    "            #with open(img_filenames[index], 'rb') as file_reader:\r\n",
    "            #    img = file_reader.read()\r\n",
    "            img = cv2.imread(img_filenames[index])\r\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "\r\n",
    "            mask = cv2.imread(label_filenames[index], 0)\r\n",
    "            masks = [(mask == v) for v in CLASS_VALUES]\r\n",
    "            mask = np.stack(masks, axis=-1).astype('float')\r\n",
    "            # add background if mask is not binary\r\n",
    "            if mask.shape[-1] != 1:\r\n",
    "                background = 1 - mask.sum(axis=-1, keepdims=True)\r\n",
    "                mask = np.concatenate((mask, background), axis=-1)\r\n",
    "\r\n",
    "            #create the required Example representation\r\n",
    "            out = parse_single_image(image=img, label=mask)\r\n",
    "            \r\n",
    "            writer.write(out.SerializeToString())\r\n",
    "            current_shard_count+=1\r\n",
    "            file_count += 1\r\n",
    "        writer.close()\r\n",
    "    print(f\"\\nWrote {file_count} elements to TFRecord\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make tf record files with train, val and test splitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for split in DATASET_SPLIT:\r\n",
    "    print(f\"Starting to process split **{split}**\")\r\n",
    "    split_img = os.path.join(DATASET_PATH, split)\r\n",
    "    split_label = os.path.join(DATASET_PATH, f\"{split}annot\")\r\n",
    "    write_image_batches_to_tfr(split_img, split_label, filename=split, max_files=MAX_FILES, out_dir=OUT_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make tf record files without train, val and test splitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(f\"Starting the process.\")\r\n",
    "split_img = os.path.join(DATASET_PATH, DATA_DIR)\r\n",
    "split_label = os.path.join(DATASET_PATH, LABEL_DIR)\r\n",
    "write_image_batches_to_tfr(split_img, split_label, filename=\"teknofest\", max_files=MAX_FILES, out_dir=OUT_PATH)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting the process.\n",
      "\n",
      "Using 0 shard(s) for 0 files, with up to 200 samples per shard\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Wrote 0 elements to TFRecord\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "92e73c2a3a66178c34ef4af89de09cfd119ed7d275422bdf7065254acf9e400f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}