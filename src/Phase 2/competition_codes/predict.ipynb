{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Here is the imports\r\n",
    "import os\r\n",
    "\r\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\r\n",
    "FLAGS = [\"\"] # load_model, load_weight, verbose\r\n",
    "from tensorflow import keras\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\r\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n",
    "import segmentation_models as sm\r\n",
    "import albumentations as A\r\n",
    "sm.set_framework(\"tf.keras\")\r\n",
    "# keras.mixed_precision.set_global_policy('mixed_float16') normally this would provide extra speed for the model\r\n",
    "# but in the case of 1660ti gpus they seem like they have tensor cores even they don't thus it slows down the model use this on higher powered models\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "AUTOTUNE = tf.data.AUTOTUNE\r\n",
    "from keras_unet_collection import models\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "from keras_unet_collection import losses\r\n",
    "import cv2\r\n",
    "from tensorflow.keras import backend as K"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataset Constants\r\n",
    "test_dir = './data/dataset1/'\r\n",
    "save_dir = './result/'\r\n",
    "IMG_EXT = 'png'\r\n",
    "BATCH_SIZE = 1\r\n",
    "LR = 0.0001\r\n",
    "# Model Constants\r\n",
    "BACKBONE = 'efficientnetb3'\r\n",
    "# unlabelled 0, iskemik 1, hemorajik 2\r\n",
    "CLASSES = ['iskemik', 'kanama']\r\n",
    "MODEL_LOAD_TYPE = 'model' # model or weights\r\n",
    "#MODEL_LOAD_TYPE = 'weights' # model or weights\r\n",
    "MODEL_PRE_TYPE = 'sm' # sm or custom\r\n",
    "#MODEL_PRE_TYPE = 'custom' # sm or custom\r\n",
    "\r\n",
    "\r\n",
    "#MODEL_WEIGHT_PATH = \"./models/14_09-07_21/best.h5\"\r\n",
    "#MODEL_WEIGHT_PATH = \"./models/10_09-01_27/best_01_27_10_09.h5\"\r\n",
    "MODEL_WEIGHT_PATH = \"./models/15_09-07_18/best.h5\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# helper function for data visualization\r\n",
    "def visualize(**images):\r\n",
    "    \"\"\"Plot images in one row.\"\"\"\r\n",
    "    n = len(images)\r\n",
    "    plt.figure(figsize=(16, 5))\r\n",
    "    for i, (name, image) in enumerate(images.items()):\r\n",
    "        plt.subplot(1, n, i + 1)\r\n",
    "        plt.xticks([])\r\n",
    "        plt.yticks([])\r\n",
    "        plt.title(' '.join(name.split('_')).title())\r\n",
    "        # if whole binary image is true plt shows it as whole image is false so for bypassing this issue we assing one pixels value to 0\r\n",
    "        image[1,1] = 0 \r\n",
    "        plt.imshow(image)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "def visualize_dataset(img, mask, classes):\r\n",
    "    kwarg = {'image': img}\r\n",
    "    for i in range(len(classes)):\r\n",
    "        kwarg.update({classes[i] : mask[..., i].squeeze()})\r\n",
    "    visualize(**kwarg)\r\n",
    "\r\n",
    "# helper function for data visualization    \r\n",
    "def denormalize(x):\r\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\r\n",
    "    x_max = np.percentile(x, 98)\r\n",
    "    x_min = np.percentile(x, 2)    \r\n",
    "    x = (x - x_min) / (x_max - x_min)\r\n",
    "    x = x.clip(0, 1)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_preprocessing(preprocessing_fn):\r\n",
    "    \"\"\"Construct preprocessing transform\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        preprocessing_fn (callbale): data normalization function \r\n",
    "            (can be specific for each pretrained neural network)\r\n",
    "    Return:\r\n",
    "        transform: albumentations.Compose\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    _transform = [\r\n",
    "        A.Lambda(image=preprocessing_fn),\r\n",
    "    ]\r\n",
    "    return A.Compose(_transform)\r\n",
    "\r\n",
    "def preprocessing_fn_sm(image):\r\n",
    "    aug = get_preprocessing(sm.get_preprocessing(BACKBONE))(image=image)\r\n",
    "    image = aug[\"image\"].astype(\"float32\")\r\n",
    "    return image \r\n",
    "\r\n",
    "def preprocessing_fn_custom(image):\r\n",
    "    image = image/255.\r\n",
    "    image = image.astype(\"float32\")\r\n",
    "    return image\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\r\n",
    "\r\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\r\n",
    "\r\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([2, 2, 0.5])) \r\n",
    "#multi_focal_tversky = losses.multiclass_focal_tversky(alpha=0.7, gamma=4/3)\r\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\r\n",
    "#total_loss = dice_loss + (1 * focal_tversky)\r\n",
    "total_loss = dice_loss + (1 * focal_loss)\r\n",
    "\r\n",
    "if MODEL_LOAD_TYPE == 'model':\r\n",
    "    model = load_model(MODEL_WEIGHT_PATH, custom_objects={'dice_loss_plus_1focal_loss': total_loss,'iou_score': sm.metrics.IOUScore(threshold=0.5), 'f1-score': sm.metrics.FScore(threshold=0.5)})\r\n",
    "elif MODEL_LOAD_TYPE == 'weights':\r\n",
    "    #create model\r\n",
    "    model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\r\n",
    "\r\n",
    "    #model = models.swin_unet_2d((512, 512, 3), filter_num_begin=64, n_labels=3, depth=3, stack_num_down=2, stack_num_up=2, \r\n",
    "    #                            patch_size=(2, 2), num_heads=[4, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \r\n",
    "    #                            output_activation='Softmax', shift_window=True, name='swin_unet')\r\n",
    "\r\n",
    "    # define optomizer\r\n",
    "    optim = keras.optimizers.Adam(LR)\r\n",
    "\r\n",
    "    multi_focal_tversky = losses.multiclass_focal_tversky(alpha=0.7, gamma=4/3)\r\n",
    "    metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]\r\n",
    "    model.compile(optim, multi_focal_tversky, metrics)\r\n",
    "    model.load_weights(MODEL_WEIGHT_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_filenames = tf.io.gfile.glob(f\"{test_dir}/*.{IMG_EXT}\")\r\n",
    "\r\n",
    "for i in predict_filenames:\r\n",
    "    img = cv2.imread(i)\r\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "    if MODEL_PRE_TYPE == \"sm\":\r\n",
    "        img = preprocessing_fn_sm(img)\r\n",
    "    elif MODEL_PRE_TYPE == \"custom\":\r\n",
    "        img = preprocessing_fn_custom(img)\r\n",
    "    pred_mask = model.predict(img)\r\n",
    "    if \"verbose\" in FLAGS:\r\n",
    "        pass # todo verbose\r\n",
    "    pred_mask = K.argmax(pred_mask, axis=-1)\r\n",
    "    cv2.imwrite(i.replace(test_dir, save_dir), pred_mask)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}