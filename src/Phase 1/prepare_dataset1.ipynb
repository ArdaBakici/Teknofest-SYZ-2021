{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "import os \r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "from tqdm import trange\r\n",
    "import random\r\n",
    "import albumentations as A"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Dataset Constants\r\n",
    "DATASET_SPLIT = {\"train\": 4977, \"val\" : 1659} # split_name: [amount_of_files, preprocessing_func] | you can leave amount of files None if you don't wan't to split\r\n",
    "NORMAL_SPLIT = {\"train\": 3310, \"val\" : 1103} # split_name: [amount_of_files, preprocessing_func] | you can leave amount of files None if you don't wan't to split\r\n",
    "ANORMAL_SPLIT = {\"train\": 1668 , \"val\" : 555}\r\n",
    "\r\n",
    "DATASET_PATH = \".\\\\data\"\r\n",
    "NORMAL_DIR = \"inme_yok\"\r\n",
    "ANORMAL_DIR = \"inme_var\"\r\n",
    "\r\n",
    "CLASS_NAMES = ['inme_yok', 'inme_var']\r\n",
    "CLASSES = [0, 1]\r\n",
    "BACKBONE = 'efficientnetb3' # enter the preprocessing for model to here, leave none if don't want to the preprocessing\r\n",
    "\r\n",
    "DATA_DIR = \"data\"\r\n",
    "LABEL_DIR = \"label\"\r\n",
    "\r\n",
    "IMG_EXT = \"png\"\r\n",
    "\r\n",
    "OUT_PATH = \"./outdata/tfrecord/\"\r\n",
    "\r\n",
    "ENCODING_TYPE = \"ZLIB\" # zlib, gzip or none - encoding  increases preprocessing time but reduces size by HUGE AMOUNTS (about %96 percent) \r\n",
    "\r\n",
    "MAX_FILES = 600"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def image_feature(value):\r\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "    return tf.train.Feature(\r\n",
    "        bytes_list=tf.train.BytesList(value=[serialize_array(value)])\r\n",
    "    )\r\n",
    "\r\n",
    "def bytes_feature(value):\r\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n",
    "    if isinstance(value, type(tf.constant(0))):\r\n",
    "        value = value.numpy()\r\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "def float_feature(value):\r\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\r\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\r\n",
    "\r\n",
    "\r\n",
    "def int64_feature(value):\r\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n",
    "\r\n",
    "def int64_feature_list(value):\r\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\r\n",
    "\r\n",
    "def float_feature_list(value):\r\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\r\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\r\n",
    "\r\n",
    "# non keras\r\n",
    "def serialize_array(array):\r\n",
    "  array = tf.io.serialize_tensor(array).numpy()\r\n",
    "  return array\r\n",
    "\r\n",
    "def get_preprocessing(preprocessing_fn):\r\n",
    "    \"\"\"Construct preprocessing transform\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        preprocessing_fn (callbale): data normalization function \r\n",
    "            (can be specific for each pretrained neural network)\r\n",
    "    Return:\r\n",
    "        transform: albumentations.Compose\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    _transform = [\r\n",
    "        A.Lambda(image=preprocessing_fn),\r\n",
    "    ]\r\n",
    "    return A.Compose(_transform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def parse_single_image(image, label):\r\n",
    "  \r\n",
    "  #define the dictionary -- the structure -- of our single example\r\n",
    "  data = {\r\n",
    "        'image' : image_feature(image),\r\n",
    "        'label' : float_feature(label)\r\n",
    "    }\r\n",
    "  #create an Example, wrapping the single features\r\n",
    "  out = tf.train.Example(features=tf.train.Features(feature=data))\r\n",
    "  return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def get_file_paths(img_normal_path, img_anormal_path, randomize=True):\r\n",
    "    img_filenames_w_labels = []\r\n",
    "    for i in tf.io.gfile.glob(f\"{img_normal_path}/*.{IMG_EXT}\"):\r\n",
    "        img_filenames_w_labels.append([i, 0])\r\n",
    "    for i in tf.io.gfile.glob(f\"{img_anormal_path}/*.{IMG_EXT}\"):\r\n",
    "        img_filenames_w_labels.append([i, 1])\r\n",
    "\r\n",
    "    if randomize:\r\n",
    "        random.shuffle(img_filenames_w_labels)\r\n",
    "\r\n",
    "    return img_filenames_w_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Processing Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def write_image_batches_to_tfr(img_w_labels, filename:str=\"batch\", max_files:int=100, out_dir:str=\"/data/tfrecord/\", augmentation=None, preprocessing=None):\r\n",
    "    num_of_files = []\r\n",
    "    for i in range(len(CLASSES)):\r\n",
    "        num_of_files.append(0)\r\n",
    "    # determine the number of shards (single TFRecord files) we need:\r\n",
    "    splits = (len(img_w_labels)//max_files) + 1\r\n",
    "    if len(img_w_labels)%max_files == 0:\r\n",
    "        splits-=1\r\n",
    "    print(f\"\\nUsing {splits} shard(s) for {len(img_w_labels)} files, with up to {max_files} samples per shard\")\r\n",
    "    os.makedirs(out_dir, exist_ok=True)\r\n",
    "    file_count = 0\r\n",
    "    for i in trange(splits):\r\n",
    "        current_shard_name = f\"{out_dir}tfrecord_{i+1}in{splits}_{filename}.tfrecords\"\r\n",
    "        if ENCODING_TYPE is not None:\r\n",
    "            options = tf.io.TFRecordOptions(compression_type=ENCODING_TYPE)\r\n",
    "            writer = tf.io.TFRecordWriter(current_shard_name, options=options)\r\n",
    "        else:\r\n",
    "            writer = tf.io.TFRecordWriter(current_shard_name)\r\n",
    "\r\n",
    "        current_shard_count = 0\r\n",
    "        while current_shard_count < max_files: #as long as our shard is not full\r\n",
    "            #get the index of the file that we want to parse now\r\n",
    "            index = i*max_files+current_shard_count\r\n",
    "            if index == len(img_w_labels): #when we have consumed the whole data, preempt generation\r\n",
    "                break\r\n",
    "            \r\n",
    "            #img = None\r\n",
    "            #with open(img_filenames[index], 'rb') as file_reader:\r\n",
    "            #    img = file_reader.read()\r\n",
    "            img = cv2.imread(img_w_labels[index][0])\r\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "\r\n",
    "            label = img_w_labels[index][1]\r\n",
    "            \r\n",
    "            for counter, value in enumerate(CLASSES):\r\n",
    "                if label == value:\r\n",
    "                    num_of_files[counter] += 1\r\n",
    "            \r\n",
    "            #create the required Example representation\r\n",
    "            out = parse_single_image(image=img, label=label)\r\n",
    "            \r\n",
    "            writer.write(out.SerializeToString())\r\n",
    "            current_shard_count+=1\r\n",
    "            file_count += 1\r\n",
    "        writer.close()\r\n",
    "    print(f\"\\nWrote {file_count} elements to TFRecord\")\r\n",
    "    for count, i in enumerate(num_of_files):\r\n",
    "        print(f\"{i} files for class {CLASS_NAMES[count]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(f\"Starting the process.\")\r\n",
    "normal_img_path = os.path.join(DATASET_PATH, NORMAL_DIR)\r\n",
    "anormal_img_path = os.path.join(DATASET_PATH, ANORMAL_DIR)\r\n",
    "\r\n",
    "img_filenames_w_labels = get_file_paths(normal_img_path, anormal_img_path, randomize=True)\r\n",
    "last_index = 0\r\n",
    "print(f\"Info: Total amount of files is {len(img_filenames_w_labels)}\")\r\n",
    "for split in DATASET_SPLIT:\r\n",
    "    file_amount = DATASET_SPLIT[split]\r\n",
    "    print(f\"Info: Starting to process split **{split}** with {file_amount} files\")\r\n",
    "    split_data = img_filenames_w_labels[last_index:last_index+file_amount]\r\n",
    "    write_image_batches_to_tfr(split_data, filename=split, max_files=MAX_FILES, out_dir=OUT_PATH, augmentation=None, preprocessing=None)\r\n",
    "    last_index = last_index+file_amount\r\n",
    "print(f\"Info: {len(img_filenames_w_labels) - last_index} left over files\")\r\n",
    "#write_image_batches_to_tfr(split_img, split_label, filename=\"teknofest\", max_files=MAX_FILES, out_dir=OUT_PATH)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting the process.\n",
      "Info: Total amount of files is 6636\n",
      "Info: Starting to process split **train** with 4977 files\n",
      "\n",
      "Using 9 shard(s) for 4977 files, with up to 600 samples per shard\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9/9 [02:31<00:00, 16.79s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Wrote 4977 elements to TFRecord\n",
      "3307 files for class inme_yok\n",
      "1670 files for class inme_var\n",
      "Info: Starting to process split **val** with 1659 files\n",
      "\n",
      "Using 3 shard(s) for 1659 files, with up to 600 samples per shard\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [01:00<00:00, 20.10s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Wrote 1659 elements to TFRecord\n",
      "1106 files for class inme_yok\n",
      "553 files for class inme_var\n",
      "Info: 0 left over files\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "92e73c2a3a66178c34ef4af89de09cfd119ed7d275422bdf7065254acf9e400f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}