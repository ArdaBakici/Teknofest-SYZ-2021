{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataset Constants\n",
    "DATASET_SPLIT = [\"training\", \"validation\", \"test\"]\n",
    "DATASET_PATH = \"dataset\"\n",
    "TRAIN_DIR = \"train\"\n",
    "VAL_DIR = \"validation\"\n",
    "TEST_DIR = \"test\"\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "LABEL_DIR = \"label\"\n",
    "\n",
    "IMG_EXT = \"png\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[serialize_array(value)])\n",
    "    )\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def create_example(image, path, example):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"path\": bytes_feature(path),\n",
    "        \"area\": float_feature(example[\"area\"]),\n",
    "        \"bbox\": float_feature_list(example[\"bbox\"]),\n",
    "        \"category_id\": int64_feature(example[\"category_id\"]),\n",
    "        \"id\": int64_feature(example[\"id\"]),\n",
    "        \"image_id\": int64_feature(example[\"image_id\"]),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"path\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"area\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"bbox\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    example[\"bbox\"] = tf.sparse.to_dense(example[\"bbox\"])\n",
    "    return example\n",
    "\n",
    "# non keras\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def parse_single_image(image, label):\n",
    "  \n",
    "  #define the dictionary -- the structure -- of our single example\n",
    "  data = {\n",
    "        'image/height' : int64_feature(image.shape[0]),\n",
    "        'image/width' : int64_feature(image.shape[1]),\n",
    "        'image/depth' : int64_feature(image.shape[2]),\n",
    "        'image/raw_image' : image_feature(image),\n",
    "        'label/raw' : image_feature(label)\n",
    "    }\n",
    "  #create an Example, wrapping the single features\n",
    "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "  return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def write_images_to_tfr_long(images, labels, filename:str=\"large_images\", max_files:int=10, out_dir:str=\"/content/\"):\n",
    "\n",
    "    #determine the number of shards (single TFRecord files) we need:\n",
    "    splits = (len(images)//max_files) + 1 #determine how many tfr shards are needed\n",
    "    if len(images)%max_files == 0:\n",
    "        splits-=1\n",
    "    print(f\"\\nUsing {splits} shard(s) for {len(images)} files, with up to {max_files} samples per shard\")\n",
    "\n",
    "    file_count = 0\n",
    "    for i in tqdm.tqdm(range(splits)):\n",
    "        current_shard_name = f\"{out_dir}{i+1}_{splits}{filename}.tfrecords\"\n",
    "        writer = tf.io.TFRecordWriter(current_shard_name)\n",
    "\n",
    "        current_shard_count = 0\n",
    "        while current_shard_count < max_files: #as long as our shard is not full\n",
    "            #get the index of the file that we want to parse now\n",
    "            index = i*max_files+current_shard_count\n",
    "            if index == len(images): #when we have consumed the whole data, preempt generation\n",
    "                break\n",
    "            current_image = images[index]\n",
    "            current_label = labels[index]\n",
    "\n",
    "            #create the required Example representation\n",
    "            out = parse_single_image(image=current_image, label=current_label)\n",
    "            \n",
    "            writer.write(out.SerializeToString())\n",
    "            current_shard_count+=1\n",
    "            file_count += 1\n",
    "        writer.close()\n",
    "    print(f\"\\nWrote {file_count} elements to TFRecord\")\n",
    "    return file_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Masks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prepare_masks(image, mask, class_values):\n",
    "    \n",
    "    # extract certain classes from mask (e.g. cars)\n",
    "    masks = [(mask == v) for v in class_values]\n",
    "    mask = np.stack(masks, axis=-1).astype('float')\n",
    "    \n",
    "    # add background if mask is not binary\n",
    "    if mask.shape[-1] != 1:\n",
    "        background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "        mask = np.concatenate((mask, background), axis=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dir = os.path.join(DATASET_PATH, TRAIN_DIR)\n",
    "val_dir = os.path.join(DATASET_PATH, VAL_DIR)\n",
    "test_dir = os.path.join(DATASET_PATH, TEST_DIR)\n",
    "train_img_dir = os.path.join(train_dir, DATA_DIR)\n",
    "train_label_dir = os.path.join(train_dir, LABEL_DIR)\n",
    "val_img_dir = os.path.join(val_dir, DATA_DIR)\n",
    "val_label_dir = os.path.join(val_dir, LABEL_DIR)\n",
    "test_img_dir = os.path.join(test_dir, DATA_DIR)\n",
    "test_val_dir = os.path.join(test_dir, LABEL_DIR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_img_filenames = tf.io.gfile.glob(f\"{train_img_dir}/*.{IMG_EXT}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "06502dce86d74bc478d17a288c655cf1bbc76b90e9d5c1d600522c777dd287fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}