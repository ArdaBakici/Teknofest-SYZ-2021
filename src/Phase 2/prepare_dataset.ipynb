{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "import tqdm\n",
    "import random"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-15 15:39:30.078656: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Dataset Constants\n",
    "DATASET_SPLIT = [\"train\", \"val\", \"test\"]\n",
    "DATASET_PATH = \"./data/dataset1\"\n",
    "TRAIN_DIR = \"train\"\n",
    "VAL_DIR = \"validation\"\n",
    "TEST_DIR = \"test\"\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "LABEL_DIR = \"label\"\n",
    "\n",
    "IMG_EXT = \"png\"\n",
    "\n",
    "OUT_PATH = \"./outdata/tfrecord/\"\n",
    "\n",
    "CLASS_VALUES = [1, 2]\n",
    "\n",
    "MAX_FILES = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[serialize_array(value)])\n",
    "    )\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"path\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"area\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"bbox\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    example[\"bbox\"] = tf.sparse.to_dense(example[\"bbox\"])\n",
    "    return example\n",
    "\n",
    "# non keras\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array).numpy()\n",
    "  return array"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def parse_single_image(image, label):\n",
    "  \n",
    "  #define the dictionary -- the structure -- of our single example\n",
    "  data = {\n",
    "        'image/height' : int64_feature(image.shape[0]),\n",
    "        'image/width' : int64_feature(image.shape[1]),\n",
    "        'image/depth' : int64_feature(image.shape[2]),\n",
    "        'image/raw_image' : image_feature(image),\n",
    "        'label/raw' : image_feature(label)\n",
    "    }\n",
    "  #create an Example, wrapping the single features\n",
    "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "  return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Processing Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def write_image_batches_to_tfr(img_path, label_path, filename:str=\"batch\", max_files:int=100, out_dir:str=\"/data/tfrecord/\"):\n",
    "    img_filenames = tf.io.gfile.glob(f\"{img_path}/*.{IMG_EXT}\")\n",
    "    random.shuffle(img_filenames)\n",
    "    label_filenames = []\n",
    "    for i in img_filenames:\n",
    "        label_filenames.append(i.replace(img_path, label_path))\n",
    "    # determine the number of shards (single TFRecord files) we need:\n",
    "    assert len(img_filenames) == len(label_filenames)\n",
    "    splits = (len(img_filenames)//max_files) + 1 #determine how many tfr shards are needed\n",
    "    if len(img_filenames)%max_files == 0:\n",
    "        splits-=1\n",
    "    print(f\"\\nUsing {splits} shard(s) for {len(img_filenames)} files, with up to {max_files} samples per shard\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    file_count = 0\n",
    "    for i in tqdm.tqdm(range(splits)):\n",
    "        current_shard_name = f\"{out_dir}tfrecord_{i+1}in{splits}_{filename}.tfrecords\"\n",
    "        writer = tf.io.TFRecordWriter(current_shard_name)\n",
    "\n",
    "        current_shard_count = 0\n",
    "        while current_shard_count < max_files: #as long as our shard is not full\n",
    "            #get the index of the file that we want to parse now\n",
    "            index = i*max_files+current_shard_count\n",
    "            if index == len(img_filenames): #when we have consumed the whole data, preempt generation\n",
    "                break\n",
    "            \n",
    "            #img = None\n",
    "            #with open(img_filenames[index], 'rb') as file_reader:\n",
    "            #    img = file_reader.read()\n",
    "            img = cv2.imread(img_filenames[index])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mask = cv2.imread(label_filenames[index], 0)\n",
    "            masks = [(mask == v) for v in CLASS_VALUES]\n",
    "            mask = np.stack(masks, axis=-1).astype('float')\n",
    "            # add background if mask is not binary\n",
    "            if mask.shape[-1] != 1:\n",
    "                background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "                mask = np.concatenate((mask, background), axis=-1)\n",
    "\n",
    "            #create the required Example representation\n",
    "            out = parse_single_image(image=img, label=mask)\n",
    "            \n",
    "            writer.write(out.SerializeToString())\n",
    "            current_shard_count+=1\n",
    "            file_count += 1\n",
    "        writer.close()\n",
    "    print(f\"\\nWrote {file_count} elements to TFRecord\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make tf record files with train, val and test splitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for split in DATASET_SPLIT:\n",
    "    print(f\"Starting to process split **{split}**\")\n",
    "    split_img = os.path.join(DATASET_PATH, split)\n",
    "    split_label = os.path.join(DATASET_PATH, f\"{split}annot\")\n",
    "    write_image_batches_to_tfr(split_img, split_label, filename=split, max_files=MAX_FILES, out_dir=OUT_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make tf record files without train, val and test splitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(f\"Starting the process.\")\n",
    "split_img = os.path.join(DATASET_PATH, DATA_DIR)\n",
    "split_label = os.path.join(DATASET_PATH, LABEL_DIR)\n",
    "write_image_batches_to_tfr(split_img, split_label, filename=\"teknofest\", max_files=MAX_FILES, out_dir=OUT_PATH)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting the process.\n",
      "\n",
      "Using 34 shard(s) for 6636 files, with up to 200 samples per shard\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 34/34 [17:15<00:00, 30.45s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Wrote 6636 elements to TFRecord\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "06502dce86d74bc478d17a288c655cf1bbc76b90e9d5c1d600522c777dd287fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}